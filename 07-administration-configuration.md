# Document 7/7 : Administration et Configuration - Projet Epercept

## Scope de ce document
Ce document final d√©finit l'administration syst√®me, les configurations d'environnement, la maintenance et les proc√©dures op√©rationnelles pour l'application Epercept. Il couvre la gestion des environnements, les outils d'administration, les proc√©dures de maintenance et la documentation op√©rationnelle.

## Autres documents du projet
- Document 1/7 : Sp√©cifications Fonctionnelles et R√®gles M√©tier ‚úì
- Document 2/7 : Design System et Exp√©rience Utilisateur ‚úì
- Document 3/7 : Architecture Backend ‚úì
- Document 4/7 : Architecture Frontend ‚úì
- Document 5/7 : S√©curit√©, Tests et DevOps ‚úì
- Document 6/7 : Performance et Scalabilit√© ‚úì

---

## 1. Configuration des Environnements

### 1.1 Variables d'environnement

#### 1.1.1 Configuration Backend (.env)
```bash
# === CONFIGURATION SERVEUR ===
NODE_ENV=production|development|staging
PORT=3001
HOST=0.0.0.0

# === BASE DE DONN√âES ===
DATABASE_URL=postgresql://user:password@localhost:5432/epercept
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=epercept
DATABASE_USER=epercept_user
DATABASE_PASSWORD=secure_password
DATABASE_SSL=true
DATABASE_POOL_MIN=2
DATABASE_POOL_MAX=10

# === REDIS CONFIGURATION ===
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=redis_password
REDIS_DB=0
REDIS_KEY_PREFIX=epercept:
REDIS_TTL=3600

# === WEBSOCKET CONFIGURATION ===
WS_CORS_ORIGINS=https://epercept.com,https://app.epercept.com
WS_MAX_CONNECTIONS=1000
WS_HEARTBEAT_INTERVAL=30000
WS_CONNECTION_TIMEOUT=60000

# === S√âCURIT√â ===
JWT_SECRET=super_secure_jwt_secret_key_min_32_chars
JWT_EXPIRATION=24h
JWT_REFRESH_EXPIRATION=7d
BCRYPT_ROUNDS=12
RATE_LIMIT_TTL=60
RATE_LIMIT_LIMIT=100

# === MONITORING ===
LOG_LEVEL=info
LOG_FORMAT=json
SENTRY_DSN=https://your-sentry-dsn
PROMETHEUS_PORT=9090
HEALTH_CHECK_ENDPOINT=/health

# === EXTERNAL SERVICES ===
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=noreply@epercept.com
SMTP_PASSWORD=smtp_password
SMTP_FROM=Epercept <noreply@epercept.com>

# === STORAGE ===
UPLOAD_PATH=./uploads
MAX_FILE_SIZE=10485760
ALLOWED_FILE_TYPES=.jpg,.jpeg,.png,.gif,.pdf

# === FEATURES FLAGS ===
ENABLE_REGISTRATION=true
ENABLE_EMAIL_VERIFICATION=true
ENABLE_ANALYTICS=true
MAINTENANCE_MODE=false
```

#### 1.1.2 Configuration Frontend (.env)
```bash
# === CONFIGURATION APPLICATION ===
VITE_APP_NAME=Epercept
VITE_APP_VERSION=1.0.0
VITE_APP_ENV=production|development|staging

# === API CONFIGURATION ===
VITE_API_BASE_URL=https://api.epercept.com
VITE_WS_URL=wss://api.epercept.com
VITE_API_TIMEOUT=10000

# === FEATURES ===
VITE_ENABLE_DEV_TOOLS=false
VITE_ENABLE_ANALYTICS=true
VITE_ENABLE_ERROR_REPORTING=true
VITE_ENABLE_PWA=true

# === EXTERNAL SERVICES ===
VITE_GOOGLE_ANALYTICS_ID=GA_MEASUREMENT_ID
VITE_SENTRY_DSN=https://your-frontend-sentry-dsn
VITE_HOTJAR_ID=your_hotjar_id

# === PWA CONFIGURATION ===
VITE_PWA_NAME=Epercept
VITE_PWA_SHORT_NAME=Epercept
VITE_PWA_DESCRIPTION=Jeu de quiz multijoueur en temps r√©el
VITE_PWA_THEME_COLOR=#1a1a1a
VITE_PWA_BACKGROUND_COLOR=#ffffff

# === BUILD CONFIGURATION ===
VITE_BUILD_SOURCEMAP=false
VITE_BUILD_MINIFY=true
VITE_BUILD_TARGET=es2020
```

### 1.2 Configuration par environnement

#### 1.2.1 Environnement de d√©veloppement
```yaml
# docker-compose.dev.yml
version: '3.8'
services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "3001:3001"
      - "9229:9229" # Debug port
    environment:
      - NODE_ENV=development
      - LOG_LEVEL=debug
    volumes:
      - .:/app
      - /app/node_modules
    depends_on:
      - postgres
      - redis

  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: epercept_dev
      POSTGRES_USER: dev_user
      POSTGRES_PASSWORD: dev_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis_dev_data:/data

volumes:
  postgres_dev_data:
  redis_dev_data:
```

#### 1.2.2 Environnement de staging
```yaml
# docker-compose.staging.yml
version: '3.8'
services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=staging
      - DATABASE_URL=${STAGING_DATABASE_URL}
      - REDIS_HOST=${STAGING_REDIS_HOST}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/staging.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
    restart: unless-stopped
```

#### 1.2.3 Environnement de production
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  app:
    image: epercept/app:latest
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_HOST=${REDIS_HOST}
      - JWT_SECRET=${JWT_SECRET}
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/prod.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
      - /var/log/nginx:/var/log/nginx
    depends_on:
      - app
    restart: always
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"
```

## 2. Outils d'Administration

### 2.1 Interface d'administration

#### 2.1.1 Panneau d'administration NestJS
```typescript
// src/admin/admin.module.ts
import { Module } from '@nestjs/common';
import { AdminController } from './admin.controller';
import { AdminService } from './admin.service';
import { AdminGuard } from './guards/admin.guard';

@Module({
  controllers: [AdminController],
  providers: [AdminService, AdminGuard],
  exports: [AdminService]
})
export class AdminModule {}

// src/admin/admin.controller.ts
import { Controller, Get, Post, Body, UseGuards, Query } from '@nestjs/common';
import { AdminGuard } from './guards/admin.guard';
import { AdminService } from './admin.service';

@Controller('admin')
@UseGuards(AdminGuard)
export class AdminController {
  constructor(private readonly adminService: AdminService) {}

  @Get('dashboard')
  async getDashboard() {
    return {
      stats: await this.adminService.getSystemStats(),
      activeGames: await this.adminService.getActiveGames(),
      recentUsers: await this.adminService.getRecentUsers()
    };
  }

  @Get('users')
  async getUsers(@Query() query: any) {
    return this.adminService.getUsers(query);
  }

  @Post('users/:id/ban')
  async banUser(@Body() banData: any) {
    return this.adminService.banUser(banData);
  }

  @Get('games')
  async getGames(@Query() query: any) {
    return this.adminService.getGames(query);
  }

  @Post('games/:id/terminate')
  async terminateGame(@Body() gameId: string) {
    return this.adminService.terminateGame(gameId);
  }

  @Get('system/health')
  async getSystemHealth() {
    return this.adminService.getSystemHealth();
  }

  @Post('system/maintenance')
  async toggleMaintenance(@Body() maintenance: boolean) {
    return this.adminService.toggleMaintenance(maintenance);
  }

  @Get('logs')
  async getLogs(@Query() query: any) {
    return this.adminService.getLogs(query);
  }
}
```

#### 2.1.2 Service d'administration
```typescript
// src/admin/admin.service.ts
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';
import { Repository } from 'typeorm';
import { User } from '../entities/user.entity';
import { Game } from '../entities/game.entity';
import { RedisService } from '../redis/redis.service';

@Injectable()
export class AdminService {
  constructor(
    @InjectRepository(User)
    private userRepository: Repository<User>,
    @InjectRepository(Game)
    private gameRepository: Repository<Game>,
    private redisService: RedisService
  ) {}

  async getSystemStats() {
    const [
      totalUsers,
      activeUsers,
      totalGames,
      activeGames
    ] = await Promise.all([
      this.userRepository.count(),
      this.userRepository.count({ where: { isActive: true }}),
      this.gameRepository.count(),
      this.gameRepository.count({ where: { status: 'active' }})
    ]);

    const memoryUsage = process.memoryUsage();
    const uptime = process.uptime();

    return {
      users: { total: totalUsers, active: activeUsers },
      games: { total: totalGames, active: activeGames },
      system: {
        uptime: Math.floor(uptime),
        memory: {
          used: Math.round(memoryUsage.heapUsed / 1024 / 1024),
          total: Math.round(memoryUsage.heapTotal / 1024 / 1024)
        }
      }
    };
  }

  async getActiveGames() {
    return this.gameRepository.find({
      where: { status: 'active' },
      relations: ['players'],
      take: 10,
      order: { createdAt: 'DESC' }
    });
  }

  async getRecentUsers(limit = 10) {
    return this.userRepository.find({
      take: limit,
      order: { createdAt: 'DESC' },
      select: ['id', 'username', 'email', 'createdAt', 'lastLogin']
    });
  }

  async banUser(banData: { userId: string, reason: string, duration?: number }) {
    const user = await this.userRepository.findOne({ 
      where: { id: banData.userId } 
    });
    
    if (!user) {
      throw new Error('Utilisateur non trouv√©');
    }

    user.isBanned = true;
    user.banReason = banData.reason;
    if (banData.duration) {
      user.banExpiresAt = new Date(Date.now() + banData.duration * 1000);
    }

    await this.userRepository.save(user);
    
    // D√©connecter l'utilisateur
    await this.redisService.del(`user_session:${user.id}`);
    
    return { success: true, message: 'Utilisateur banni avec succ√®s' };
  }

  async terminateGame(gameId: string) {
    const game = await this.gameRepository.findOne({ 
      where: { id: gameId },
      relations: ['players']
    });
    
    if (!game) {
      throw new Error('Partie non trouv√©e');
    }

    game.status = 'terminated';
    game.endedAt = new Date();
    
    await this.gameRepository.save(game);
    
    // Notifier les joueurs via WebSocket
    // Implementation WebSocket notification...
    
    return { success: true, message: 'Partie termin√©e avec succ√®s' };
  }

  async toggleMaintenance(enabled: boolean) {
    await this.redisService.set('maintenance_mode', enabled.toString());
    return { 
      success: true, 
      message: `Mode maintenance ${enabled ? 'activ√©' : 'd√©sactiv√©'}` 
    };
  }

  async getSystemHealth() {
    const checks = {
      database: await this.checkDatabase(),
      redis: await this.checkRedis(),
      memory: this.checkMemory(),
      disk: await this.checkDisk()
    };

    const isHealthy = Object.values(checks).every(check => check.status === 'ok');

    return {
      status: isHealthy ? 'healthy' : 'unhealthy',
      checks,
      timestamp: new Date().toISOString()
    };
  }

  private async checkDatabase() {
    try {
      await this.userRepository.query('SELECT 1');
      return { status: 'ok', message: 'Base de donn√©es accessible' };
    } catch (error) {
      return { status: 'error', message: error.message };
    }
  }

  private async checkRedis() {
    try {
      await this.redisService.ping();
      return { status: 'ok', message: 'Redis accessible' };
    } catch (error) {
      return { status: 'error', message: error.message };
    }
  }

  private checkMemory() {
    const usage = process.memoryUsage();
    const usedMB = Math.round(usage.heapUsed / 1024 / 1024);
    const totalMB = Math.round(usage.heapTotal / 1024 / 1024);
    const percentage = Math.round((usedMB / totalMB) * 100);

    return {
      status: percentage > 90 ? 'warning' : 'ok',
      message: `M√©moire utilis√©e: ${usedMB}MB / ${totalMB}MB (${percentage}%)`
    };
  }

  private async checkDisk() {
    // Implementation du check espace disque
    return { status: 'ok', message: 'Espace disque suffisant' };
  }
}
```

### 2.2 Scripts d'administration

#### 2.2.1 Scripts de gestion des utilisateurs
```bash
#!/bin/bash
# scripts/admin/user-management.sh

# Configuration
API_BASE_URL="http://localhost:3001"
ADMIN_TOKEN="${ADMIN_JWT_TOKEN}"

show_help() {
    echo "Usage: $0 [COMMAND] [OPTIONS]"
    echo ""
    echo "Commands:"
    echo "  list           Liste les utilisateurs"
    echo "  ban USER_ID    Bannir un utilisateur"
    echo "  unban USER_ID  D√©bannir un utilisateur"
    echo "  stats          Afficher les statistiques"
    echo ""
    echo "Options:"
    echo "  -h, --help     Afficher cette aide"
    echo "  -v, --verbose  Mode verbeux"
}

list_users() {
    local limit=${1:-10}
    echo "üìã Liste des utilisateurs (limite: $limit)"
    
    curl -s -H "Authorization: Bearer $ADMIN_TOKEN" \
         "$API_BASE_URL/admin/users?limit=$limit" | \
         jq -r '.[] | "\(.id) | \(.username) | \(.email) | \(.createdAt)"' | \
         column -t -s '|'
}

ban_user() {
    local user_id=$1
    local reason=${2:-"Violation des conditions d'utilisation"}
    
    if [ -z "$user_id" ]; then
        echo "‚ùå ID utilisateur requis"
        exit 1
    fi
    
    echo "üö´ Bannissement de l'utilisateur $user_id..."
    
    response=$(curl -s -X POST \
        -H "Authorization: Bearer $ADMIN_TOKEN" \
        -H "Content-Type: application/json" \
        -d "{\"userId\":\"$user_id\",\"reason\":\"$reason\"}" \
        "$API_BASE_URL/admin/users/$user_id/ban")
    
    if echo "$response" | jq -e '.success' > /dev/null; then
        echo "‚úÖ Utilisateur banni avec succ√®s"
    else
        echo "‚ùå Erreur lors du bannissement: $(echo "$response" | jq -r '.message')"
    fi
}

unban_user() {
    local user_id=$1
    
    if [ -z "$user_id" ]; then
        echo "‚ùå ID utilisateur requis"
        exit 1
    fi
    
    echo "‚úÖ D√©bannissement de l'utilisateur $user_id..."
    
    response=$(curl -s -X POST \
        -H "Authorization: Bearer $ADMIN_TOKEN" \
        -H "Content-Type: application/json" \
        -d "{\"userId\":\"$user_id\"}" \
        "$API_BASE_URL/admin/users/$user_id/unban")
    
    if echo "$response" | jq -e '.success' > /dev/null; then
        echo "‚úÖ Utilisateur d√©banni avec succ√®s"
    else
        echo "‚ùå Erreur lors du d√©bannissement: $(echo "$response" | jq -r '.message')"
    fi
}

show_stats() {
    echo "üìä Statistiques du syst√®me"
    
    stats=$(curl -s -H "Authorization: Bearer $ADMIN_TOKEN" \
                 "$API_BASE_URL/admin/dashboard")
    
    echo "$stats" | jq -r '
        "Utilisateurs:",
        "  Total: \(.stats.users.total)",
        "  Actifs: \(.stats.users.active)",
        "",
        "Parties:",
        "  Total: \(.stats.games.total)",
        "  Actives: \(.stats.games.active)",
        "",
        "Syst√®me:",
        "  Uptime: \(.stats.system.uptime)s",
        "  M√©moire: \(.stats.system.memory.used)MB / \(.stats.system.memory.total)MB"
    '
}

# Traitement des arguments
case $1 in
    list)
        list_users $2
        ;;
    ban)
        ban_user $2 "$3"
        ;;
    unban)
        unban_user $2
        ;;
    stats)
        show_stats
        ;;
    -h|--help)
        show_help
        ;;
    *)
        echo "‚ùå Commande inconnue: $1"
        show_help
        exit 1
        ;;
esac
```

#### 2.2.2 Scripts de maintenance
```bash
#!/bin/bash
# scripts/admin/maintenance.sh

# Configuration
BACKUP_DIR="/backups/epercept"
LOG_DIR="/var/log/epercept"
DB_NAME="epercept"
DB_USER="epercept_user"

show_help() {
    echo "Usage: $0 [COMMAND] [OPTIONS]"
    echo ""
    echo "Commands:"
    echo "  backup         Cr√©er une sauvegarde compl√®te"
    echo "  restore FILE   Restaurer depuis une sauvegarde"
    echo "  cleanup        Nettoyer les fichiers temporaires"
    echo "  logs           Afficher les logs r√©cents"
    echo "  health         V√©rifier l'√©tat du syst√®me"
    echo ""
}

create_backup() {
    local timestamp=$(date +"%Y%m%d_%H%M%S")
    local backup_file="$BACKUP_DIR/epercept_backup_$timestamp.tar.gz"
    
    echo "üíæ Cr√©ation de la sauvegarde..."
    
    # Cr√©er le r√©pertoire de sauvegarde
    mkdir -p "$BACKUP_DIR"
    
    # Sauvegarde de la base de donn√©es
    echo "üìä Sauvegarde de la base de donn√©es..."
    pg_dump -h localhost -U $DB_USER -d $DB_NAME > "$BACKUP_DIR/db_$timestamp.sql"
    
    # Sauvegarde des fichiers upload√©s
    echo "üìÅ Sauvegarde des fichiers..."
    if [ -d "./uploads" ]; then
        cp -r ./uploads "$BACKUP_DIR/uploads_$timestamp"
    fi
    
    # Sauvegarde des configurations
    echo "‚öôÔ∏è Sauvegarde des configurations..."
    cp .env "$BACKUP_DIR/env_$timestamp" 2>/dev/null || true
    cp docker-compose.prod.yml "$BACKUP_DIR/docker-compose_$timestamp.yml" 2>/dev/null || true
    
    # Cr√©ation de l'archive
    echo "üì¶ Cr√©ation de l'archive..."
    cd "$BACKUP_DIR"
    tar -czf "$backup_file" \
        "db_$timestamp.sql" \
        "uploads_$timestamp" \
        "env_$timestamp" \
        "docker-compose_$timestamp.yml" 2>/dev/null
    
    # Nettoyage des fichiers temporaires
    rm -rf "db_$timestamp.sql" "uploads_$timestamp" "env_$timestamp" "docker-compose_$timestamp.yml"
    
    echo "‚úÖ Sauvegarde cr√©√©e: $backup_file"
    
    # Nettoyage des anciennes sauvegardes (garde les 7 derni√®res)
    find "$BACKUP_DIR" -name "epercept_backup_*.tar.gz" -type f -mtime +7 -delete
    echo "üßπ Anciennes sauvegardes supprim√©es"
}

restore_backup() {
    local backup_file=$1
    
    if [ -z "$backup_file" ] || [ ! -f "$backup_file" ]; then
        echo "‚ùå Fichier de sauvegarde invalide"
        exit 1
    fi
    
    echo "üîÑ Restauration depuis $backup_file..."
    
    # Confirmation
    read -p "‚ö†Ô∏è Cette op√©ration va √©craser les donn√©es actuelles. Continuer? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "‚ùå Restauration annul√©e"
        exit 1
    fi
    
    # Extraction de l'archive
    local temp_dir=$(mktemp -d)
    tar -xzf "$backup_file" -C "$temp_dir"
    
    # Restauration de la base de donn√©es
    echo "üìä Restauration de la base de donn√©es..."
    db_file=$(find "$temp_dir" -name "db_*.sql" | head -1)
    if [ -f "$db_file" ]; then
        psql -h localhost -U $DB_USER -d $DB_NAME < "$db_file"
    fi
    
    # Restauration des fichiers
    echo "üìÅ Restauration des fichiers..."
    uploads_dir=$(find "$temp_dir" -name "uploads_*" -type d | head -1)
    if [ -d "$uploads_dir" ]; then
        rm -rf ./uploads
        mv "$uploads_dir" ./uploads
    fi
    
    # Nettoyage
    rm -rf "$temp_dir"
    
    echo "‚úÖ Restauration termin√©e"
}

cleanup_system() {
    echo "üßπ Nettoyage du syst√®me..."
    
    # Nettoyage des logs anciens
    find "$LOG_DIR" -name "*.log" -type f -mtime +30 -delete 2>/dev/null || true
    echo "üìù Logs anciens supprim√©s"
    
    # Nettoyage des fichiers temporaires
    find /tmp -name "epercept_*" -type f -mtime +1 -delete 2>/dev/null || true
    echo "üóëÔ∏è Fichiers temporaires supprim√©s"
    
    # Nettoyage Docker
    if command -v docker &> /dev/null; then
        docker system prune -f
        echo "üê≥ Cache Docker nettoy√©"
    fi
    
    # Nettoyage des uploads orphelins
    # Implementation specific cleanup logic...
    
    echo "‚úÖ Nettoyage termin√©"
}

show_logs() {
    local lines=${1:-100}
    echo "üìù Logs r√©cents ($lines lignes):"
    
    if [ -f "$LOG_DIR/app.log" ]; then
        tail -n $lines "$LOG_DIR/app.log"
    else
        echo "‚ùå Fichier de log non trouv√©: $LOG_DIR/app.log"
    fi
}

check_health() {
    echo "üè• V√©rification de l'√©tat du syst√®me..."
    
    # V√©rification de l'API
    if curl -sf http://localhost:3001/health > /dev/null; then
        echo "‚úÖ API accessible"
    else
        echo "‚ùå API inaccessible"
    fi
    
    # V√©rification de la base de donn√©es
    if pg_isready -h localhost -U $DB_USER > /dev/null 2>&1; then
        echo "‚úÖ Base de donn√©es accessible"
    else
        echo "‚ùå Base de donn√©es inaccessible"
    fi
    
    # V√©rification de Redis
    if redis-cli ping > /dev/null 2>&1; then
        echo "‚úÖ Redis accessible"
    else
        echo "‚ùå Redis inaccessible"
    fi
    
    # V√©rification de l'espace disque
    disk_usage=$(df -h / | awk 'NR==2 {print $5}' | sed 's/%//')
    if [ "$disk_usage" -lt 90 ]; then
        echo "‚úÖ Espace disque suffisant ($disk_usage%)"
    else
        echo "‚ö†Ô∏è Espace disque faible ($disk_usage%)"
    fi
    
    # V√©rification de la m√©moire
    mem_usage=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100.0}')
    if [ "$mem_usage" -lt 90 ]; then
        echo "‚úÖ M√©moire suffisante ($mem_usage%)"
    else
        echo "‚ö†Ô∏è M√©moire √©lev√©e ($mem_usage%)"
    fi
}

# Traitement des arguments
case $1 in
    backup)
        create_backup
        ;;
    restore)
        restore_backup $2
        ;;
    cleanup)
        cleanup_system
        ;;
    logs)
        show_logs $2
        ;;
    health)
        check_health
        ;;
    -h|--help)
        show_help
        ;;
    *)
        echo "‚ùå Commande inconnue: $1"
        show_help
        exit 1
        ;;
esac
```

## 3. Proc√©dures de Maintenance

### 3.1 Maintenance pr√©ventive

#### 3.1.1 Checklist de maintenance hebdomadaire
```markdown
# Checklist de Maintenance Hebdomadaire - Epercept

## Syst√®me et Infrastructure
- [ ] V√©rifier l'√©tat des services (API, Base de donn√©es, Redis)
- [ ] Contr√¥ler l'utilisation des ressources (CPU, RAM, Disque)
- [ ] V√©rifier les logs d'erreur et les alertes
- [ ] Tester les sauvegardes automatiques
- [ ] V√©rifier les certificats SSL (expiration)
- [ ] Contr√¥ler les mises √† jour de s√©curit√© disponibles

## Base de Donn√©es
- [ ] V√©rifier la taille de la base de donn√©es
- [ ] Analyser les requ√™tes lentes
- [ ] Optimiser les index si n√©cessaire
- [ ] V√©rifier l'int√©grit√© des donn√©es
- [ ] Nettoyer les donn√©es expir√©es/orphelines

## Performance
- [ ] Analyser les m√©triques de performance
- [ ] V√©rifier les temps de r√©ponse API
- [ ] Contr√¥ler l'utilisation du cache Redis
- [ ] Analyser le trafic et les pics de charge

## S√©curit√©
- [ ] V√©rifier les tentatives d'intrusion dans les logs
- [ ] Contr√¥ler les connexions suspectes
- [ ] V√©rifier les tokens JWT expir√©s
- [ ] Analyser les rapports de s√©curit√© automatiques

## Utilisateurs et Contenu
- [ ] V√©rifier les comptes utilisateurs suspects
- [ ] Contr√¥ler les rapports de mod√©ration
- [ ] Analyser l'activit√© des utilisateurs
- [ ] V√©rifier les statistiques d'utilisation

## Documentation
- [ ] Mettre √† jour la documentation technique
- [ ] Documenter les incidents et r√©solutions
- [ ] V√©rifier la validit√© des proc√©dures
```

#### 3.1.2 Proc√©dure de mise √† jour
```bash
#!/bin/bash
# scripts/admin/update-system.sh

BACKUP_REQUIRED=true
DOWNTIME_EXPECTED=true
ROLLBACK_AVAILABLE=true

show_help() {
    echo "Proc√©dure de mise √† jour du syst√®me Epercept"
    echo "Usage: $0 [VERSION] [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  --no-backup    Ignorer la sauvegarde pr√©alable"
    echo "  --no-downtime  Mise √† jour sans interruption"
    echo "  --dry-run      Simulation sans application"
}

pre_update_checks() {
    echo "üîç V√©rifications pr√©-mise √† jour..."
    
    # V√©rifier l'√©tat du syst√®me
    if ! ./maintenance.sh health; then
        echo "‚ùå Syst√®me non pr√™t pour la mise √† jour"
        exit 1
    fi
    
    # V√©rifier l'espace disque
    disk_free=$(df -BG / | awk 'NR==2 {print $4}' | sed 's/G//')
    if [ "$disk_free" -lt 5 ]; then
        echo "‚ùå Espace disque insuffisant (${disk_free}GB disponible)"
        exit 1
    fi
    
    # V√©rifier les processus critiques
    if ! pgrep -f "node.*server.js" > /dev/null; then
        echo "‚ùå Application non d√©marr√©e"
        exit 1
    fi
    
    echo "‚úÖ V√©rifications termin√©es"
}

create_pre_update_backup() {
    if [ "$BACKUP_REQUIRED" = true ]; then
        echo "üíæ Cr√©ation de la sauvegarde pr√©-mise √† jour..."
        ./maintenance.sh backup
        
        if [ $? -ne 0 ]; then
            echo "‚ùå √âchec de la sauvegarde"
            exit 1
        fi
        
        echo "‚úÖ Sauvegarde cr√©√©e"
    fi
}

enable_maintenance_mode() {
    if [ "$DOWNTIME_EXPECTED" = true ]; then
        echo "üöß Activation du mode maintenance..."
        
        # Activer le mode maintenance via API
        curl -X POST \
             -H "Authorization: Bearer $ADMIN_TOKEN" \
             -H "Content-Type: application/json" \
             -d '{"enabled": true}' \
             http://localhost:3001/admin/system/maintenance
        
        # Attendre que les connexions actuelles se terminent
        sleep 30
        
        echo "‚úÖ Mode maintenance activ√©"
    fi
}

update_application() {
    local version=$1
    echo "üîÑ Mise √† jour vers la version $version..."
    
    # Arr√™ter l'application
    docker-compose down
    
    # Sauvegarder la version actuelle
    docker tag epercept/app:latest epercept/app:backup-$(date +%Y%m%d_%H%M%S)
    
    # T√©l√©charger la nouvelle version
    docker pull epercept/app:$version
    docker tag epercept/app:$version epercept/app:latest
    
    # Mettre √† jour les configurations si n√©cessaire
    if [ -f "update-configs.sh" ]; then
        ./update-configs.sh $version
    fi
    
    # Appliquer les migrations de base de donn√©es
    if [ -f "migrate.sh" ]; then
        ./migrate.sh
    fi
    
    # Red√©marrer l'application
    docker-compose up -d
    
    # Attendre que l'application soit pr√™te
    echo "‚è≥ Attente du d√©marrage de l'application..."
    timeout=300
    while [ $timeout -gt 0 ]; do
        if curl -sf http://localhost:3001/health > /dev/null; then
            break
        fi
        sleep 5
        timeout=$((timeout - 5))
    done
    
    if [ $timeout -le 0 ]; then
        echo "‚ùå L'application n'a pas d√©marr√© dans les temps"
        return 1
    fi
    
    echo "‚úÖ Application mise √† jour et d√©marr√©e"
}

post_update_tests() {
    echo "üß™ Tests post-mise √† jour..."
    
    # Test de sant√© de l'API
    if ! curl -sf http://localhost:3001/health > /dev/null; then
        echo "‚ùå API non accessible"
        return 1
    fi
    
    # Test de connexion WebSocket
    # Implementation WebSocket test...
    
    # Test de base de donn√©es
    if ! ./maintenance.sh health | grep -q "Base de donn√©es accessible"; then
        echo "‚ùå Base de donn√©es inaccessible"
        return 1
    fi
    
    # Tests fonctionnels automatis√©s
    if [ -f "run-smoke-tests.sh" ]; then
        ./run-smoke-tests.sh
        if [ $? -ne 0 ]; then
            echo "‚ùå Tests fonctionnels √©chou√©s"
            return 1
        fi
    fi
    
    echo "‚úÖ Tests termin√©s avec succ√®s"
}

disable_maintenance_mode() {
    if [ "$DOWNTIME_EXPECTED" = true ]; then
        echo "üü¢ D√©sactivation du mode maintenance..."
        
        curl -X POST \
             -H "Authorization: Bearer $ADMIN_TOKEN" \
             -H "Content-Type: application/json" \
             -d '{"enabled": false}' \
             http://localhost:3001/admin/system/maintenance
        
        echo "‚úÖ Mode maintenance d√©sactiv√©"
    fi
}

rollback_update() {
    echo "üîÑ Rollback de la mise √† jour..."
    
    # R√©activer le mode maintenance
    enable_maintenance_mode
    
    # Restaurer la version pr√©c√©dente
    docker-compose down
    docker tag epercept/app:backup-$(date +%Y%m%d_%H%M%S) epercept/app:latest
    
    # Restaurer la base de donn√©es si n√©cessaire
    latest_backup=$(ls -t /backups/epercept/epercept_backup_*.tar.gz | head -1)
    if [ -f "$latest_backup" ]; then
        ./maintenance.sh restore "$latest_backup"
    fi
    
    # Red√©marrer l'application
    docker-compose up -d
    
    # D√©sactiver le mode maintenance
    disable_maintenance_mode
    
    echo "‚úÖ Rollback termin√©"
}

# Fonction principale de mise √† jour
main() {
    local version=$1
    
    if [ -z "$version" ]; then
        echo "‚ùå Version requise"
        show_help
        exit 1
    fi
    
    echo "üöÄ D√©but de la mise √† jour vers la version $version"
    
    # V√©rifications pr√©alables
    pre_update_checks
    
    # Sauvegarde
    create_pre_update_backup
    
    # Mode maintenance
    enable_maintenance_mode
    
    # Mise √† jour
    if update_application $version; then
        # Tests post-mise √† jour
        if post_update_tests; then
            # D√©sactiver le mode maintenance
            disable_maintenance_mode
            echo "‚úÖ Mise √† jour termin√©e avec succ√®s"
        else
            echo "‚ùå Tests post-mise √† jour √©chou√©s"
            rollback_update
            exit 1
        fi
    else
        echo "‚ùå √âchec de la mise √† jour"
        rollback_update
        exit 1
    fi
}

# Traitement des arguments
case $1 in
    -h|--help)
        show_help
        ;;
    --dry-run)
        echo "üß™ Mode simulation activ√©"
        # Implementation dry-run mode...
        ;;
    *)
        main $1
        ;;
esac
```

### 3.2 Gestion des incidents

#### 3.2.1 Proc√©dure de gestion des incidents
```markdown
# Proc√©dure de Gestion des Incidents - Epercept

## Classification des Incidents

### Niveau 1 - Critique
- Application compl√®tement inaccessible
- Perte de donn√©es utilisateur
- Faille de s√©curit√© majeure
- **SLA**: R√©solution < 1 heure

### Niveau 2 - Majeur  
- Fonctionnalit√©s principales indisponibles
- Performance tr√®s d√©grad√©e
- Erreurs affectant >50% des utilisateurs
- **SLA**: R√©solution < 4 heures

### Niveau 3 - Mineur
- Fonctionnalit√©s secondaires affect√©es
- Erreurs affectant <10% des utilisateurs
- Probl√®mes cosm√©tiques
- **SLA**: R√©solution < 24 heures

## Proc√©dure d'Escalade

### D√©tection
1. **Monitoring automatique** (Prometheus/Grafana)
2. **Alertes utilisateurs** (Support/Feedback)
3. **Surveillance manuelle** (√âquipe technique)

### R√©ponse Imm√©diate
1. **√âvaluation** de la criticit√©
2. **Communication** aux parties prenantes
3. **Activation** de l'√©quipe d'intervention
4. **Isolation** du probl√®me si possible

### Investigation
1. **Collecte** des logs et m√©triques
2. **Reproduction** du probl√®me
3. **Identification** de la cause racine
4. **Documentation** des findings

### R√©solution
1. **Impl√©mentation** du correctif
2. **Tests** en environnement de staging
3. **D√©ploiement** en production
4. **Validation** de la r√©solution

### Post-Incident
1. **Post-mortem** d√©taill√©
2. **Actions correctives** identifi√©es
3. **Mise √† jour** des proc√©dures
4. **Communication** finale aux utilisateurs
```

#### 3.2.2 Scripts de diagnostic
```bash
#!/bin/bash
# scripts/admin/diagnostic.sh

LOG_DIR="/var/log/epercept"
OUTPUT_DIR="/tmp/diagnostic_$(date +%Y%m%d_%H%M%S)"

generate_diagnostic_report() {
    echo "üîç G√©n√©ration du rapport de diagnostic..."
    mkdir -p "$OUTPUT_DIR"
    
    # Informations syst√®me
    echo "=== INFORMATIONS SYST√àME ===" > "$OUTPUT_DIR/system_info.txt"
    uname -a >> "$OUTPUT_DIR/system_info.txt"
    uptime >> "$OUTPUT_DIR/system_info.txt"
    free -h >> "$OUTPUT_DIR/system_info.txt"
    df -h >> "$OUTPUT_DIR/system_info.txt"
    
    # √âtat des services
    echo "=== √âTAT DES SERVICES ===" > "$OUTPUT_DIR/services_status.txt"
    systemctl status postgresql >> "$OUTPUT_DIR/services_status.txt" 2>&1
    systemctl status redis >> "$OUTPUT_DIR/services_status.txt" 2>&1
    systemctl status nginx >> "$OUTPUT_DIR/services_status.txt" 2>&1
    
    # √âtat Docker
    echo "=== √âTAT DOCKER ===" > "$OUTPUT_DIR/docker_status.txt"
    docker ps -a >> "$OUTPUT_DIR/docker_status.txt"
    docker stats --no-stream >> "$OUTPUT_DIR/docker_status.txt"
    
    # Logs applicatifs
    echo "=== LOGS APPLICATIFS ===" > "$OUTPUT_DIR/app_logs.txt"
    tail -n 1000 "$LOG_DIR/app.log" >> "$OUTPUT_DIR/app_logs.txt" 2>/dev/null
    
    # Logs d'erreur
    echo "=== LOGS D'ERREUR ===" > "$OUTPUT_DIR/error_logs.txt"
    tail -n 500 "$LOG_DIR/error.log" >> "$OUTPUT_DIR/error_logs.txt" 2>/dev/null
    
    # M√©triques de performance
    echo "=== M√âTRIQUES PERFORMANCE ===" > "$OUTPUT_DIR/performance.txt"
    curl -s http://localhost:9090/metrics >> "$OUTPUT_DIR/performance.txt" 2>/dev/null
    
    # Configuration actuelle
    echo "=== CONFIGURATION ===" > "$OUTPUT_DIR/config.txt"
    docker-compose config >> "$OUTPUT_DIR/config.txt" 2>/dev/null
    
    # Cr√©er l'archive
    tar -czf "/tmp/diagnostic_report_$(date +%Y%m%d_%H%M%S).tar.gz" -C "$OUTPUT_DIR" .
    rm -rf "$OUTPUT_DIR"
    
    echo "‚úÖ Rapport de diagnostic g√©n√©r√©: /tmp/diagnostic_report_$(date +%Y%m%d_%H%M%S).tar.gz"
}

check_connectivity() {
    echo "üåê V√©rification de la connectivit√©..."
    
    # Test API locale
    if curl -sf http://localhost:3001/health > /dev/null; then
        echo "‚úÖ API locale accessible"
    else
        echo "‚ùå API locale inaccessible"
    fi
    
    # Test base de donn√©es
    if pg_isready -h localhost > /dev/null 2>&1; then
        echo "‚úÖ Base de donn√©es accessible"
    else
        echo "‚ùå Base de donn√©es inaccessible"
    fi
    
    # Test Redis
    if redis-cli ping > /dev/null 2>&1; then
        echo "‚úÖ Redis accessible"
    else
        echo "‚ùå Redis inaccessible"
    fi
    
    # Test DNS
    if nslookup google.com > /dev/null 2>&1; then
        echo "‚úÖ R√©solution DNS fonctionnelle"
    else
        echo "‚ùå Probl√®me de r√©solution DNS"
    fi
}

analyze_performance() {
    echo "üìä Analyse des performances..."
    
    # CPU et m√©moire
    echo "CPU Usage: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | sed 's/%us,//')"
    echo "Memory Usage: $(free | grep Mem | awk '{printf "%.2f%%", $3/$2 * 100.0}')"
    
    # Analyse des processus
    echo "Top 10 des processus par CPU:"
    ps aux --sort=-%cpu | head -11
    
    echo "Top 10 des processus par m√©moire:"
    ps aux --sort=-%mem | head -11
    
    # Analyse de la base de donn√©es
    echo "Analyse de la base de donn√©es:"
    psql -h localhost -U epercept_user -d epercept -c "
        SELECT 
            query,
            calls,
            total_time,
            mean_time,
            rows
        FROM pg_stat_statements 
        ORDER BY total_time DESC 
        LIMIT 10;
    " 2>/dev/null || echo "pg_stat_statements non disponible"
}

check_disk_space() {
    echo "üíΩ V√©rification de l'espace disque..."
    
    # Espace disque global
    df -h
    
    # R√©pertoires les plus volumineux
    echo "R√©pertoires les plus volumineux:"
    du -sh /* 2>/dev/null | sort -hr | head -10
    
    # Fichiers de logs volumineux
    echo "Fichiers de logs volumineux:"
    find /var/log -type f -size +100M -exec ls -lh {} \; 2>/dev/null
}

case $1 in
    report)
        generate_diagnostic_report
        ;;
    connectivity)
        check_connectivity
        ;;
    performance)
        analyze_performance
        ;;
    disk)
        check_disk_space
        ;;
    all)
        check_connectivity
        analyze_performance
        check_disk_space
        generate_diagnostic_report
        ;;
    *)
        echo "Usage: $0 {report|connectivity|performance|disk|all}"
        exit 1
        ;;
esac
```

## 4. Documentation Op√©rationnelle

### 4.1 Runbook de d√©ploiement

#### 4.1.1 Checklist de d√©ploiement production
```markdown
# Checklist de D√©ploiement Production - Epercept

## Pr√©-d√©ploiement

### Code et Tests
- [ ] **Code Review** complet effectu√©
- [ ] **Tests unitaires** passent (>90% coverage)
- [ ] **Tests d'int√©gration** passent
- [ ] **Tests e2e** passent
- [ ] **Tests de performance** valid√©s
- [ ] **Analyse de s√©curit√©** effectu√©e

### Infrastructure
- [ ] **Environnement de staging** test√©
- [ ] **Capacit√© serveur** v√©rifi√©e
- [ ] **Certificats SSL** valides
- [ ] **DNS** configur√© correctement
- [ ] **CDN** configur√© et test√©

### Base de Donn√©es
- [ ] **Migrations** test√©es sur staging
- [ ] **Sauvegarde** pr√©-d√©ploiement cr√©√©e
- [ ] **Plan de rollback** d√©fini
- [ ] **Indexes** optimis√©s

### Configurations
- [ ] **Variables d'environnement** v√©rifi√©es
- [ ] **Secrets** mis √† jour si n√©cessaire
- [ ] **Feature flags** configur√©s
- [ ] **Limites de taux** ajust√©es

## D√©ploiement

### √âtapes de D√©ploiement
- [ ] **Mode maintenance** activ√©
- [ ] **Sauvegarde** pr√©-d√©ploiement effectu√©e
- [ ] **Code** d√©ploy√© sur les serveurs
- [ ] **Migrations** de base de donn√©es ex√©cut√©es
- [ ] **Services** red√©marr√©s
- [ ] **Cache** invalid√©
- [ ] **CDN** mis √† jour

### V√©rifications
- [ ] **Health checks** passent
- [ ] **Logs** v√©rifi√©s (pas d'erreurs)
- [ ] **Performance** dans les seuils acceptables
- [ ] **Fonctionnalit√©s critiques** test√©es
- [ ] **Monitoring** activ√©

## Post-d√©ploiement

### Surveillance
- [ ] **M√©triques** surveill√©es pendant 1h
- [ ] **Alertes** configur√©es
- [ ] **Logs d'erreur** v√©rifi√©s
- [ ] **Performance** monitored
- [ ] **Trafic utilisateur** normal

### Communication
- [ ] **√âquipe** notifi√©e du succ√®s
- [ ] **Utilisateurs** inform√©s si n√©cessaire
- [ ] **Documentation** mise √† jour
- [ ] **Mode maintenance** d√©sactiv√©
- [ ] **Post-mortem** planifi√© si incidents

## Rollback d'Urgence

### Conditions de Rollback
- [ ] **Erreurs critiques** d√©tect√©es
- [ ] **Performance** inacceptable (>5s response time)
- [ ] **Indisponibilit√©** des fonctionnalit√©s principales
- [ ] **Corruption** de donn√©es d√©tect√©e

### Proc√©dure de Rollback
- [ ] **Mode maintenance** r√©activ√©
- [ ] **Version pr√©c√©dente** red√©ploy√©e
- [ ] **Base de donn√©es** restaur√©e si n√©cessaire
- [ ] **Cache** invalid√©
- [ ] **Services** red√©marr√©s
- [ ] **V√©rifications** post-rollback
```

### 4.2 Guide de troubleshooting

#### 4.2.1 Probl√®mes courants et solutions
```markdown
# Guide de Troubleshooting - Epercept

## Probl√®mes d'API

### API inaccessible (500 Internal Server Error)

**Sympt√¥mes:**
- Impossible d'acc√©der √† l'API
- Status 500 sur toutes les routes
- Application frontend ne peut pas se connecter

**Diagnostic:**
```bash
# V√©rifier l'√©tat du service
systemctl status epercept-api

# V√©rifier les logs
tail -f /var/log/epercept/app.log

# V√©rifier la connectivit√© base de donn√©es
pg_isready -h localhost -U epercept_user
```

**Solutions:**
1. **Red√©marrer le service:**
   ```bash
   systemctl restart epercept-api
   ```

2. **V√©rifier la configuration:**
   ```bash
   # V√©rifier les variables d'environnement
   docker exec epercept-app env | grep -E "(DATABASE|REDIS|JWT)"
   ```

3. **V√©rifier les d√©pendances:**
   ```bash
   # PostgreSQL
   systemctl restart postgresql
   
   # Redis
   systemctl restart redis
   ```

### Lenteur de l'API (>5s response time)

**Sympt√¥mes:**
- Temps de r√©ponse √©lev√©
- Timeouts c√¥t√© client
- Charge √©lev√©e sur le serveur

**Diagnostic:**
```bash
# Analyser les performances
./scripts/admin/diagnostic.sh performance

# V√©rifier les requ√™tes lentes
psql -h localhost -U epercept_user -d epercept -c "
  SELECT query, calls, total_time, mean_time 
  FROM pg_stat_statements 
  ORDER BY total_time DESC LIMIT 10;
"

# V√©rifier l'utilisation m√©moire Redis
redis-cli info memory
```

**Solutions:**
1. **Optimiser les requ√™tes lentes**
2. **Augmenter les resources serveur**
3. **Optimiser le cache Redis**
4. **Ajouter des indexes sur la base de donn√©es**

## Probl√®mes WebSocket

### Connexions WebSocket qui √©chouent

**Sympt√¥mes:**
- Impossible de rejoindre une partie
- Messages temps r√©el non re√ßus
- Erreurs de connexion WebSocket

**Diagnostic:**
```bash
# Tester la connexion WebSocket
wscat -c ws://localhost:3001

# V√©rifier les logs WebSocket
grep "websocket" /var/log/epercept/app.log
```

**Solutions:**
1. **V√©rifier la configuration du proxy:**
   ```nginx
   # nginx.conf
   location /socket.io/ {
       proxy_pass http://backend;
       proxy_http_version 1.1;
       proxy_set_header Upgrade $http_upgrade;
       proxy_set_header Connection "upgrade";
   }
   ```

2. **Red√©marrer le service WebSocket**

### Messages perdus ou dupliqu√©s

**Diagnostic:**
```bash
# V√©rifier les m√©triques Redis
redis-cli info stats

# Analyser les logs de messages
grep "message_sent\|message_received" /var/log/epercept/app.log
```

## Probl√®mes de Base de Donn√©es

### Connexions √† la base de donn√©es √©puis√©es

**Sympt√¥mes:**
- Erreur "too many connections"
- API lente ou inaccessible
- Timeouts de base de donn√©es

**Diagnostic:**
```sql
-- V√©rifier les connexions actives
SELECT count(*) FROM pg_stat_activity;

-- Identifier les connexions longues
SELECT pid, now() - pg_stat_activity.query_start AS duration, query 
FROM pg_stat_activity 
WHERE (now() - pg_stat_activity.query_start) > interval '5 minutes';
```

**Solutions:**
1. **Augmenter le pool de connexions:**
   ```bash
   # Dans .env
   DATABASE_POOL_MAX=20
   ```

2. **Tuer les connexions longues:**
   ```sql
   SELECT pg_terminate_backend(pid) FROM pg_stat_activity 
   WHERE state = 'idle' AND now() - state_change > interval '1 hour';
   ```

### Performance d√©grad√©e

**Diagnostic:**
```sql
-- Analyser les requ√™tes lentes
SELECT query, calls, total_time, mean_time, rows
FROM pg_stat_statements 
ORDER BY total_time DESC LIMIT 10;

-- V√©rifier les indexes manquants
SELECT schemaname, tablename, attname, n_distinct, correlation 
FROM pg_stats WHERE schemaname = 'public';
```

## Probl√®mes Redis

### Redis inaccessible

**Diagnostic:**
```bash
# Tester la connexion
redis-cli ping

# V√©rifier l'√©tat du service
systemctl status redis

# Analyser les logs
tail -f /var/log/redis/redis-server.log
```

**Solutions:**
1. **Red√©marrer Redis:**
   ```bash
   systemctl restart redis
   ```

2. **V√©rifier la configuration:**
   ```bash
   redis-cli config get "*"
   ```

### M√©moire Redis pleine

**Diagnostic:**
```bash
redis-cli info memory
redis-cli config get maxmemory*
```

**Solutions:**
1. **Augmenter la m√©moire allou√©e:**
   ```bash
   redis-cli config set maxmemory 2gb
   ```

2. **Configurer l'√©viction:**
   ```bash
   redis-cli config set maxmemory-policy allkeys-lru
   ```

## Probl√®mes Frontend

### Application ne se charge pas

**Sympt√¥mes:**
- Page blanche
- Erreurs JavaScript dans la console
- Ressources non trouv√©es (404)

**Diagnostic:**
```bash
# V√©rifier le serveur web
curl -I http://localhost:80

# V√©rifier les logs nginx
tail -f /var/log/nginx/error.log

# Tester les ressources statiques
curl -I http://localhost:80/assets/main.js
```

**Solutions:**
1. **Reconstruire l'application:**
   ```bash
   npm run build
   ```

2. **V√©rifier la configuration nginx:**
   ```nginx
   location / {
       try_files $uri $uri/ /index.html;
   }
   ```

### Probl√®mes de performance frontend

**Diagnostic:**
- Utiliser les DevTools du navigateur
- Analyser les m√©triques Core Web Vitals
- V√©rifier le cache des ressources

**Solutions:**
1. **Optimiser les bundles JavaScript**
2. **Impl√©menter le lazy loading**
3. **Optimiser les images**
4. **Configurer la mise en cache**
```

#### 4.2.2 Contacts et escalade
```markdown
# Contacts d'Urgence - Epercept

## √âquipe Technique

### Lead Developer
- **Nom:** [NOM_LEAD_DEV]
- **Email:** lead.dev@epercept.com
- **T√©l√©phone:** [PHONE_EMERGENCY]
- **Disponibilit√©:** 24/7 pour les incidents critiques

### DevOps Engineer
- **Nom:** [NOM_DEVOPS]
- **Email:** devops@epercept.com
- **T√©l√©phone:** [PHONE_DEVOPS]
- **Disponibilit√©:** Lun-Ven 8h-18h, on-call weekend

### System Administrator
- **Nom:** [NOM_SYSADMIN]
- **Email:** sysadmin@epercept.com
- **T√©l√©phone:** [PHONE_SYSADMIN]
- **Disponibilit√©:** 24/7 pour les incidents infrastructure

## Prestataires Externes

### H√©bergeur (OVH/AWS)
- **Support:** [SUPPORT_PROVIDER]
- **Account Manager:** [ACCOUNT_MANAGER]
- **SLA:** 99.9% uptime garanti

### Monitoring (DataDog/New Relic)
- **Support:** [MONITORING_SUPPORT]
- **Documentation:** [MONITORING_DOCS]

## Proc√©dure d'Escalade

### Niveau 1 (0-30 min)
- √âquipe technique de garde
- Investigation et premi√®re r√©solution

### Niveau 2 (30-60 min)
- Lead Developer contact√©
- Escalade prestataires si n√©cessaire

### Niveau 3 (60+ min)
- Management technique impliqu√©
- Communication utilisateurs
- Plan de communication crise activ√©

## Canaux de Communication

### Slack
- **Canal urgence:** #epercept-incidents
- **Canal tech:** #epercept-tech
- **Canal alerts:** #epercept-alerts

### Email
- **Incidents:** incidents@epercept.com
- **Tech Team:** tech@epercept.com
- **Management:** management@epercept.com

### Status Page
- **URL:** status.epercept.com
- **Admin:** statuspage-admin@epercept.com
```

## 5. R√©capitulatif et Prochaines √âtapes

### 5.1 Documentation compl√®te r√©alis√©e

Ce document **7/7** compl√®te la s√©rie compl√®te de sp√©cifications techniques pour le projet Epercept :

1. ‚úÖ **Sp√©cifications Fonctionnelles et R√®gles M√©tier**
2. ‚úÖ **Design System et Exp√©rience Utilisateur**
3. ‚úÖ **Architecture Backend (NestJS)**
4. ‚úÖ **Architecture Frontend (React/TypeScript)**
5. ‚úÖ **S√©curit√©, Tests et DevOps**
6. ‚úÖ **Performance et Scalabilit√©**
7. ‚úÖ **Administration et Configuration** (ce document)

### 5.2 √âl√©ments cl√©s de l'administration

#### Configuration d'environnement compl√®te
- Variables d'environnement pour tous les environnements
- Configuration Docker pour dev/staging/production
- Scripts de configuration automatis√©s

#### Outils d'administration robustes
- Interface d'administration NestJS int√©gr√©e
- Scripts de gestion des utilisateurs et maintenance
- Proc√©dures de mise √† jour automatis√©es avec rollback

#### Proc√©dures op√©rationnelles d√©finies
- Maintenance pr√©ventive hebdomadaire
- Gestion des incidents avec SLA d√©finis
- Documentation de troubleshooting compl√®te

#### Monitoring et diagnostic
- Scripts de diagnostic automatis√©s
- Proc√©dures d'escalade claires
- Contacts d'urgence d√©finis

### 5.3 Prochaines √©tapes recommand√©es

#### Phase 1 : Mise en place de l'infrastructure
1. **Configurer les environnements** selon les sp√©cifications
2. **Impl√©menter les scripts d'administration**
3. **Mettre en place le monitoring** (Prometheus/Grafana)
4. **Configurer les alertes** automatiques

#### Phase 2 : Tests et validation
1. **Tester les proc√©dures de d√©ploiement**
2. **Valider les scripts de sauvegarde/restauration**
3. **Effectuer des tests de charge** sur l'infrastructure
4. **Simuler des pannes** pour valider les proc√©dures

#### Phase 3 : Formation et documentation
1. **Former l'√©quipe** aux proc√©dures op√©rationnelles
2. **Cr√©er la documentation utilisateur** pour l'interface admin
3. **√âtablir les processus** de maintenance pr√©ventive
4. **Mettre en place la veille** technologique et s√©curit√©

---

**Cette s√©rie de 7 documents fournit une base solide et compl√®te pour le d√©veloppement, le d√©ploiement et la maintenance de l'application Epercept. Chaque document est con√ßu pour √™tre utilis√© de mani√®re autonome tout en s'int√©grant parfaitement dans l'architecture globale du projet.**